{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12031420,"sourceType":"datasetVersion","datasetId":7125218}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/PKU-VCL-3DV/SLAM3R.git\n%cd SLAM3R","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:25:43.098655Z","iopub.execute_input":"2025-06-02T04:25:43.098819Z","iopub.status.idle":"2025-06-02T04:25:46.941319Z","shell.execute_reply.started":"2025-06-02T04:25:43.098805Z","shell.execute_reply":"2025-06-02T04:25:46.940472Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'SLAM3R'...\nremote: Enumerating objects: 182, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (11/11), done.\u001b[K\nremote: Total 182 (delta 19), reused 16 (delta 16), pack-reused 155 (from 1)\u001b[K\nReceiving objects: 100% (182/182), 22.96 MiB | 9.31 MiB/s, done.\nResolving deltas: 100% (80/80), done.\n/kaggle/working/SLAM3R\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!python -V","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:25:46.943373Z","iopub.execute_input":"2025-06-02T04:25:46.943666Z","iopub.status.idle":"2025-06-02T04:25:47.068632Z","shell.execute_reply.started":"2025-06-02T04:25:46.943634Z","shell.execute_reply":"2025-06-02T04:25:47.067759Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.11\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# install torch according to your cuda version\n!pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 -U\n!pip install opencv-python \n!pip install -r requirements.txt -U\n# optional: install additional packages to support visualization and data preprocessing\n!pip install -r requirements_optional.txt -U","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:25:47.069620Z","iopub.execute_input":"2025-06-02T04:25:47.069823Z"}},"outputs":[{"name":"stdout","text":"Collecting torch==2.5.0\n  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting torchvision==0.20.0\n  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\nCollecting torchaudio==2.5.0\n  Downloading torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.1.0 (from torch==2.5.0)\n  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0) (11.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.20.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.20.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.20.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.20.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.20.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.20.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.20.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.20.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.20.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.20.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.20.0) (2024.2.0)\nDownloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, torchvision\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# install XFormers according to your pytorch version, see https://github.com/facebookresearch/xformers\n!pip install xformers==0.0.28.post2\n# compile cuda kernels for RoPE\n%cd slam3r/pos_embed/curope/\n!python setup.py build_ext --inplace\n!cd ../../../","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from slam3r.models import Image2PointsModel, Local2WorldModel\nImage2PointsModel.from_pretrained('siyan824/slam3r_i2p')\nLocal2WorldModel.from_pretrained('siyan824/slam3r_l2w')\npass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import cv2 as cv\n# import numpy as np\n# import os\n# import yaml\n# from tqdm import tqdm\n\n\n# def load_camera_params(yaml_path: str):\n#     \"\"\"\n#     Load camera intrinsic and extrinsic parameters from a ROS-style YAML file.\n#     \"\"\"\n#     with open(yaml_path, \"r\") as f:\n#         data = yaml.safe_load(f)\n\n#     cam_matrix = np.array(data[\"camera_matrix\"][\"data\"]).reshape((3, 3))\n#     dist_coeffs = np.array(data[\"distortion_coefficients\"][\"data\"]).reshape((1, 5))\n#     rect_matrix = np.array(data[\"rectification_matrix\"][\"data\"]).reshape((3, 3))\n#     proj_matrix = np.array(data[\"projection_matrix\"][\"data\"]).reshape((3, 4))\n#     return cam_matrix, dist_coeffs, rect_matrix, proj_matrix\n\n\n# def rectify_image(img: np.ndarray, cam_matrix, dist_coeffs, rect_matrix, proj_matrix):\n#     \"\"\"\n#     Apply stereo rectification and undistortion to a single image.\n#     \"\"\"\n#     h, w = img.shape[:2]\n#     image_size = (w, h)\n#     mapx, mapy = cv.initUndistortRectifyMap(\n#         cam_matrix, dist_coeffs, rect_matrix, proj_matrix, image_size, cv.CV_32FC1\n#     )\n#     return cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n\n\n# def save_image(img: np.ndarray, path: str):\n#     os.makedirs(os.path.dirname(path), exist_ok=True)\n#     cv.imwrite(path, img)\n\n\n# def split_stereo_frame(frame: np.ndarray):\n#     \"\"\"\n#     Split a side-by-side stereo frame into (right_image, left_image).\n#     左图在右边，右图在左边（按用户要求）\n#     \"\"\"\n#     h, w = frame.shape[:2]\n#     mid = w // 2\n#     right_img = frame[:, :mid]\n#     left_img = frame[:, mid:]\n#     return left_img, right_img  # 顺序为 (左相机, 右相机)\n\n\n# def extract_rectified_images_from_video(\n#     video_path: str,\n#     output_dir: str,\n#     frame_idces,\n#     calib_paths: list[str] | None = None,\n# ):\n#     \"\"\"\n#     Extract a rectified stereo pair from a specific frame in a video.\n#     Saves the left and right image, with left on the right side of the stereo pair.\n#     \"\"\"\n#     if not os.path.exists(video_path):\n#         raise FileNotFoundError(f\"Video not found: {video_path}\")\n    \n#     cap = cv.VideoCapture(video_path)\n#     if not cap.isOpened():\n#         raise IOError(f\"Failed to open video: {video_path}\")\n#     left_paths, right_paths = [], []\n#     for frame_idx in tqdm(frame_idces):\n#         cap.set(cv.CAP_PROP_POS_FRAMES, frame_idx)\n#         ret, frame = cap.read()\n#         # cap.release()\n    \n#         if not ret:\n#             raise ValueError(f\"Could not read frame {frame_idx} from video.\")\n    \n#         # 分割图像：左侧是右相机，右侧是左相机\n#         left_img, right_img = split_stereo_frame(frame)\n    \n#         # 输出路径\n#         left_path = os.path.join(output_dir, f\"{frame_idx:06d}.jpg\")\n#         # right_path = os.path.join(output_dir, f\"{frame_idx:06d}_right.jpg\")\n    \n#         # 如果提供了标定文件，进行矫正\n#         if calib_paths:\n#             left_calib, right_calib = calib_paths\n#             camL, distL, rectL, projL = load_camera_params(left_calib)\n#             camR, distR, rectR, projR = load_camera_params(right_calib)\n    \n#             left_img = rectify_image(left_img, camL, distL, rectL, projL)\n#             right_img = rectify_image(right_img, camR, distR, rectR, projR)\n    \n#         save_image(left_img, left_path)\n#         # save_image(right_img, right_path)\n#         left_paths.append(left_path)\n#         # right_paths.append(right_path)\n\n#     return left_paths, right_paths\n#     # return left_img, right_img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video_path = \"/kaggle/input/slam3r-paperboxtestimense/testimenta.avi\"\noutput_dir = \"data\"\nframe_idx = 0\ncalib_left = \"/kaggle/input/slam3r-paperboxtestimense/left.yaml\"\ncalib_right = \"/kaggle/input/slam3r-paperboxtestimense/right.yaml\"\ncalib_paths = [calib_left, calib_right]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from  matplotlib import pyplot as plt\n%matplotlib inline\ndef cv2_img2plt_img(cv2_img: np.ndarray)-> np.ndarray:\n    if cv2_img.ndim==3: # Color image, Convert BGR to RGB\n        return cv2_img[:,:,::-1] \n    else: # Grayscale image\n        return cv2_img\n\ndef jshow(cv2_img: np.ndarray, size: int = 4)-> None:\n    plt.figure(figsize=(size, size))\n    plt.imshow(cv2_img2plt_img(cv2_img), plt.cm.gray)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -frv data\nos.makedirs(output_dir, exist_ok=True)\n\n# left, right = extract_rectified_images_from_video(video_path, output_dir, range(0, 800, 3), calib_paths)\n# cv.imwrite(f\"{output_dir}/{i:06d}.png\", left)\n\n!ls data | wc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vid = cv2.VideoCapture(video_path)\ni = 0\nwhile True:\n    _, frame = vid.read()\n    if not _: \n        print(f\"{i=} image saved\")\n        break\n    cv2.imwrite(f\"data/{i:02d}.png\", frame)\n    \n!ls data | wc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import cv2\n# import os\n# import numpy as np\n# from  matplotlib import pyplot as plt\n# %matplotlib inline\n# def cv2_img2plt_img(cv2_img: np.ndarray)-> np.ndarray:\n#     if cv2_img.ndim==3: # Color image, Convert BGR to RGB\n#         return cv2_img[:,:,::-1] \n#     else: # Grayscale image\n#         return cv2_img\n\n# def jshow(cv2_img: np.ndarray, size: int = 4)-> None:\n#     plt.figure(figsize=(size, size))\n#     plt.imshow(cv2_img2plt_img(cv2_img), plt.cm.gray)\n#     plt.show()\n    \n# # --- Paths ---\n# video_path = \"/kaggle/input/slam3r-paperboxtestimense/Suuicha.mp4\"\n# output_folder = \"data\"\n\n# # --- Create output folder if it doesn't exist ---\n# os.makedirs(output_folder, exist_ok=True)\n\n# # # --- Hardcoded camera parameters from right.yaml ---\n# # K = np.array([\n# #     [513.49236,   0.0,     338.19594],\n# #     [0.0,     514.03728, 256.53249],\n# #     [0.0,       0.0,       1.0     ]\n# # ])\n\n# # D = np.array([0.694361, -0.252790, -0.023128, -0.000022, 0.000000])  # distortion coefficients\n# # image_size = (640, 480)  # width, height\n\n# # # --- Precompute undistortion maps ---\n# # map1, map2 = cv2.initUndistortRectifyMap(\n# #     K, D, R=np.eye(3), newCameraMatrix=K,\n# #     size=image_size, m1type=cv2.CV_16SC2\n# # )\n\n# # 原始图像尺寸\n# w, h = 640, 480\n\n# fx = 390.11869\n# fy = 383.49252\n# cx = 328.46914\n# cy = 256.1368\n# focal_length = 414.95255  # 单位：像素\n# baseline = 0.054          # 单位：米（请根据实际情况修改）\n\n# # 相机内参矩阵\n# K = np.array([[fx,   0.     , cx],\n#               [  0.     , fy, cy ],\n#               [  0.     ,   0.     ,   1.     ]])\n\n# # 畸变参数 [k1, k2, p1, p2, k3]\n# dist = np.array([0.147781, -0.143127, -0.001289, 0.000231, 0.0])\n\n# # 获取新的相机内参（保留全部视野，alpha=1）\n# new_K, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), alpha=1)\n\n# # 生成映射矩阵\n# map1, map2 = cv2.initUndistortRectifyMap(K, dist, None, new_K, (w, h), cv2.CV_16SC2)\n\n# def lr_undist(left, right):\n#     left_img_un = cv2.remap(left, map1, map2, interpolation=cv2.INTER_LINEAR)\n#     right_img_un = cv2.remap(right, map1, map2, interpolation=cv2.INTER_LINEAR)\n#     return left_img_un, right_img_un\n\n# # --- Open video ---\n# cap = cv2.VideoCapture(video_path)\n# if not cap.isOpened():\n#     print(\"Error: Could not open video.\")\n#     exit()\n\n# frame_count = 0\n# while cap.isOpened():\n#     ret, frame = cap.read()\n#     if not ret:\n#         break\n\n#     # Crop right camera view (left half)\n#     frame_right, frame_left = frame[:, 0:640, :], frame[:, 640:, :]\n\n#     # Undistort the cropped frame\n#     # undistorted = cv2.remap(frame_right, map1, map2, interpolation=cv2.INTER_LINEAR)\n#     left_un, right_un = lr_undist(frame_left, frame_right)\n#     jshow(left_un)\n#     jshow(frame_left)\n#     # Save the undistorted frame\n#     output_path = os.path.join(output_folder, f\"frame_{frame_count:06d}.png\")\n\n#     cv2.imwrite(output_path, left_un)\n#     frame_count += 1\n#     break\n\n# cap.release()\n# print(f\"Extracted and undistorted {frame_count} frames to '{output_folder}'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !bash scripts/demo_wild.sh\n\ncmd = \"\"\"\n#!/bin/bash\n\n\n######################################################################################\n# set the img_dir below to the directory of the set of images you want to reconstruct\n# set the postfix below to the format of the rgb images in the img_dir\n######################################################################################\n\nTEST_DATASET=\"Seq_Data(img_dir='/kaggle/input/slam3r-paperboxtestimense/compet_pool', postfix='.jpg', \\\nimg_size=224, silent=False, sample_freq=1, \\\nstart_idx=0, num_views=-1, start_freq=1, to_tensor=True)\"\n\n######################################################################################\n# set the parameters for whole scene reconstruction below\n# for defination of these parameters, please refer to the recon.py\n######################################################################################\nTEST_NAME=\"paper_box_test\"\nKEYFRAME_STRIDE=-1     #-1 for auto-adaptive keyframe stride selection\nWIN_R=5\nMAX_NUM_REGISTER=10\nNUM_SCENE_FRAME=10\nINITIAL_WINSIZE=5\nCONF_THRES_L2W=12\nCONF_THRES_I2P=1.5\nNUM_POINTS_SAVE=1000000\n\nUPDATE_BUFFER_INTV=1\nBUFFER_SIZE=-1       # -1 if size is not limited\nBUFFER_STRATEGY=\"reservoir\"  # or \"fifo\"\n\nKEYFRAME_ADAPT_MIN=1\nKEYFRAME_ADAPT_MAX=20\nKEYFRAME_ADAPT_STRIDE=1\n\nGPU_ID=-1\n\npython recon.py \\\n--test_name $TEST_NAME \\\n--dataset \"${TEST_DATASET}\" \\\n--gpu_id $GPU_ID \\\n--keyframe_stride $KEYFRAME_STRIDE \\\n--win_r $WIN_R \\\n--num_scene_frame $NUM_SCENE_FRAME \\\n--initial_winsize $INITIAL_WINSIZE \\\n--conf_thres_l2w $CONF_THRES_L2W \\\n--conf_thres_i2p $CONF_THRES_I2P \\\n--num_points_save $NUM_POINTS_SAVE \\\n--update_buffer_intv $UPDATE_BUFFER_INTV \\\n--buffer_size $BUFFER_SIZE \\\n--buffer_strategy \"${BUFFER_STRATEGY}\" \\\n--max_num_register $MAX_NUM_REGISTER \\\n--keyframe_adapt_min $KEYFRAME_ADAPT_MIN \\\n--keyframe_adapt_max $KEYFRAME_ADAPT_MAX \\\n--keyframe_adapt_stride $KEYFRAME_ADAPT_STRIDE \\\n--save_preds\n\n\"\"\"\nwith open(\"test_paper_box.sh\", 'w') as f:\n    f.write(cmd)\n!ls\n!cat test_paper_box.sh","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!time bash test_paper_box.sh","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp ./results/paper_box_test/data_recon.ply /kaggle/working/\n!zip /kaggle/working/result.zip ./results -r\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pwd\n!ls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}