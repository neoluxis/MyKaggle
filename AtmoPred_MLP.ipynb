{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":56537,"databundleVersionId":8015876,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport polars as pl\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-04T16:47:16.964386Z","iopub.execute_input":"2024-05-04T16:47:16.964790Z","iopub.status.idle":"2024-05-04T16:47:18.056931Z","shell.execute_reply.started":"2024-05-04T16:47:16.964752Z","shell.execute_reply":"2024-05-04T16:47:18.055853Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/leap-atmospheric-physics-ai-climsim/sample_submission.csv\n/kaggle/input/leap-atmospheric-physics-ai-climsim/train.csv\n/kaggle/input/leap-atmospheric-physics-ai-climsim/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom sklearn.metrics import r2_score\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:47:18.058828Z","iopub.execute_input":"2024-05-04T16:47:18.059314Z","iopub.status.idle":"2024-05-04T16:47:24.552418Z","shell.execute_reply.started":"2024-05-04T16:47:18.059267Z","shell.execute_reply":"2024-05-04T16:47:24.551399Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# 读取数据\ntrain_csv = '/kaggle/input/leap-atmospheric-physics-ai-climsim/train.csv'\ntest_csv = '/kaggle/input/leap-atmospheric-physics-ai-climsim/test.csv'\nsubm_spl = '/kaggle/input/leap-atmospheric-physics-ai-climsim/sample_submission.csv'\nout_csv = 'submission.csv'\n\nread_chunk_size = 100000 # 一次性读取100000行数据\n\n# 训练参数\nnum_epochs = 50\nmax_patience = 3\nbatch_size = 360\nnum_workers = 256\nlr = 0.0005\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:47:24.553603Z","iopub.execute_input":"2024-05-04T16:47:24.554066Z","iopub.status.idle":"2024-05-04T16:47:24.591780Z","shell.execute_reply.started":"2024-05-04T16:47:24.554038Z","shell.execute_reply":"2024-05-04T16:47:24.590724Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def graph(acc, loss, title):\n    \"\"\" 绘制准确率和损失曲线\n\n    Args:\n        acc (list): [train, val]/[test]\n        loss (list): [train, val]/[test]\n        title (str): Title\n    \"\"\"\n    assert len(acc) == len(loss), 'Length of acc and loss must be the same'\n    global save_run_dir\n    if len(acc) == 2:\n        plt.subplot(1, 2, 1)\n        plt.plot(acc[0], label='Training Accuracy')\n        plt.plot(acc[1], label='Validation Accuracy')\n        plt.title(title)\n        plt.ylabel('Accuracy')\n        plt.xlabel('Epoch')\n        plt.legend()\n        plt.subplot(1, 2, 2)\n        plt.plot(loss[0], label='Training Loss')\n        plt.plot(loss[1], label='Validation Loss')\n        plt.ylabel('Loss')\n        plt.xlabel('Epoch')\n        plt.legend()\n    elif len(acc) == 1:\n        plt.subplot(2, 1, 1)\n        plt.plot(acc[0], label='Test Accuracy')\n        plt.title(title)\n        plt.ylabel('Accuracy')\n        plt.xlabel('Epoch')\n        plt.legend()\n        plt.subplot(2, 1, 2)\n        plt.plot(loss[0], label='Test Loss')\n        plt.ylabel('Loss')\n        plt.xlabel('Epoch')\n        plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:47:24.594911Z","iopub.execute_input":"2024-05-04T16:47:24.595586Z","iopub.status.idle":"2024-05-04T16:47:24.608837Z","shell.execute_reply.started":"2024-05-04T16:47:24.595547Z","shell.execute_reply":"2024-05-04T16:47:24.607783Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import time\n\nclass Timer:\n    def __init__(self):\n        self.t0 = 0\n        self.t1 = 0\n        self.times = []\n        self.infos = []\n        \n    def start(self, info = 'Run'):\n        self.t1 = self.t0\n        self.infos.append(f'{len(self.infos)} {info}')\n        self.t0 = time.time()\n        \n    def stop(self):\n        self.t1 = time.time()\n        t = self.t1 - self.t0\n        self.times.append(t)\n        print(f'{self.infos[-1]} Time Cost: {t:.3f}s')\n        \n    def get_stats(self):\n        for info, tm in zip(self.infos, self.times):\n            print(f'{info}\\t{tm:.3f}s')\n        print(f'Total: {sum(self.times):.3f} ')\n    \n    def clear(self, idx=0):\n        if idx == 0:\n            self.infos.clear()\n            self.times.clear()\n            return\n        info = self.infos.pop(idx - (0 if idx < 0 else 1))\n        tm = self.times.pop(idx - (0 if idx < 0 else 1))\n        return info, tm\n        \ntimer = Timer()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:47:24.610511Z","iopub.execute_input":"2024-05-04T16:47:24.611185Z","iopub.status.idle":"2024-05-04T16:47:24.624154Z","shell.execute_reply.started":"2024-05-04T16:47:24.611149Z","shell.execute_reply":"2024-05-04T16:47:24.623246Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 读取数据\ntimer.start(f'Read dataset chunk size {read_chunk_size}')\ntrain_chunks = pd.read_csv(train_csv, chunksize = read_chunk_size)\ntrain_data = next(train_chunks)\ntimer.stop()\n# train_data = next(train_chunks)\n# train_data = next(train_chunks)\ncols = train_data.columns\n\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:47:24.625642Z","iopub.execute_input":"2024-05-04T16:47:24.626646Z","iopub.status.idle":"2024-05-04T16:48:03.851596Z","shell.execute_reply.started":"2024-05-04T16:47:24.626614Z","shell.execute_reply":"2024-05-04T16:48:03.850781Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0 Read dataset chunk size 100000 Time Cost: 39.211s\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(100000, 925)"},"metadata":{}}]},{"cell_type":"markdown","source":"# 划分数据集\n\n1. 划分数据的输入输出\n2. 划分 训练集，验证集(，测试集)","metadata":{}},{"cell_type":"code","source":"# 划分数据集\n\ndef split_io(dframe, in_cols = cols[1:557], out_cols = cols[557:]):\n    # 划分输入输出\n    in_df = dframe[in_cols]\n    out_df = dframe[out_cols]\n    return in_df, out_df\n\ndef split_tvt(dframe, ratio=[0.8], shuffle=False):\n    # 设定好 train (和 val) 集的比例，剩余的均归到test/val\n    assert sum(ratio) <= 1, \"Ratio sum for train and val cannot be bigger than 1\"\n    assert len(ratio) > 0, \"Ratio cannot be empty\"\n     # 根据是否需要测试集来调整比例\n    train_rat = ratio[0]\n    val_rat = (1 - train_rat) if len(ratio) == 1 else ratio[1]\n    test_rat = (1 - train_rat - val_rat) if len(ratio) == 2 else 0\n    \n    data_size = dframe.shape[0]\n    train_size = int(data_size * train_rat)\n    val_size = (data_size - train_size) if len(ratio) == 1 else int(data_size * val_rat)\n    \n    if shuffle:\n        dframe = dframe.sample(frac=1).reset_index(drop=True)\n        \n    train = dframe.iloc[:train_size]\n    val = dframe.iloc[train_size:train_size + val_size]\n    \n    if test_rat != 0:\n        test = dframe.iloc[train_size + val_size:]\n        return train, val, test\n    else:\n        return train, val","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:03.852935Z","iopub.execute_input":"2024-05-04T16:48:03.853309Z","iopub.status.idle":"2024-05-04T16:48:03.862939Z","shell.execute_reply.started":"2024-05-04T16:48:03.853276Z","shell.execute_reply":"2024-05-04T16:48:03.861810Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 划分数据集\ntrain_set, val_set, test_set = split_tvt(train_data, [0.7, 0.2], True)\ntrain_in, train_out = split_io(train_set)\nval_in, val_out = split_io(val_set)\ntest_in, test_out = split_io(test_set)\n\nprint(f'{val_set.shape = }')\nprint(f'{test_set.shape = }')\nprint(f'{train_in.shape = }')\nprint(f'{train_out.shape = }')\nprint(f'{val_in.shape = }')\nprint(f'{val_out.shape = }')\n# print(f'{val_out.iloc[0] = }')\n\ndel(train_data)\ndel(train_set)\ndel(val_set)\ndel(test_set)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:03.864214Z","iopub.execute_input":"2024-05-04T16:48:03.864514Z","iopub.status.idle":"2024-05-04T16:48:04.839458Z","shell.execute_reply.started":"2024-05-04T16:48:03.864490Z","shell.execute_reply":"2024-05-04T16:48:04.838483Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"val_set.shape = (20000, 925)\ntest_set.shape = (10000, 925)\ntrain_in.shape = (70000, 556)\ntrain_out.shape = (70000, 368)\nval_in.shape = (20000, 556)\nval_out.shape = (20000, 368)\n","output_type":"stream"}]},{"cell_type":"code","source":"class MLP_Dataset(Dataset):\n    def __init__(self, dsin, dsout, transform = transforms.Compose([\n        transforms.ToTensor(),\n    ])):\n        self.dsin = dsin\n        self.dsout = dsout\n        self.transform =transform\n    \n    def __len__(self):\n        return self.dsin.shape[0]\n    \n    def __getitem__(self, idx):\n        data, targ =  self.dsin.iloc[idx], self.dsout.iloc[idx]\n        data, targ = data.to_numpy().reshape((1, 556)), targ.to_numpy().reshape((1, 368))\n        data, targ = torch.tensor(data), torch.tensor(targ)\n        data, targ = data.to(torch.float32), targ.to(torch.float32)\n        return data, targ","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.840647Z","iopub.execute_input":"2024-05-04T16:48:04.840902Z","iopub.status.idle":"2024-05-04T16:48:04.848527Z","shell.execute_reply.started":"2024-05-04T16:48:04.840875Z","shell.execute_reply":"2024-05-04T16:48:04.847691Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset = MLP_Dataset(train_in, train_out)\n# print(f'{train_dataset[0][0].shape = } {train_dataset[0][1].shape = } {len(train_dataset) = }')\ntrain_loader =  DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\nprint(f'{len(train_loader) = }')\n\nval_dataset = MLP_Dataset(val_in, val_out)\nval_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\nprint(f'{len(val_loader) = }')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.852349Z","iopub.execute_input":"2024-05-04T16:48:04.852613Z","iopub.status.idle":"2024-05-04T16:48:04.865442Z","shell.execute_reply.started":"2024-05-04T16:48:04.852591Z","shell.execute_reply":"2024-05-04T16:48:04.864331Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"len(train_loader) = 195\nlen(val_loader) = 56\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 256 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_chunk_loader(chunk, test = False):\n    tmr = Timer()\n    tmr.start('Load datasets...')\n    train_set, val_set = split_tvt(chunk)\n    train_in, train_out = split_io(train_set)\n    val_in, val_out = split_io(val_set)\n    print(f'{train_in.shape = }')\n    print(f'{train_out.shape = }')\n    print(f'{val_in.shape = }')\n    print(f'{val_out.shape = }')\n    train_dataset = MLP_Dataset(train_in, train_out)\n    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n    print(f'{len(train_loader) = }')\n\n    val_dataset = MLP_Dataset(val_in, val_out)\n    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    print(f'{len(val_loader) = }')\n    tmr.stop()\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.866547Z","iopub.execute_input":"2024-05-04T16:48:04.866812Z","iopub.status.idle":"2024-05-04T16:48:04.874008Z","shell.execute_reply.started":"2024-05-04T16:48:04.866790Z","shell.execute_reply":"2024-05-04T16:48:04.873214Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Define MLP","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, layers=5, hidden=144):\n        super(MLP, self).__init__()\n        self.hidden = hidden\n        self.linear = nn.Sequential(\n            nn.Linear(556, hidden),\n            nn.ReLU(),\n            nn.Dropout(),\n            *[nn.LazyLinear(hidden),\n            nn.LazyBatchNorm1d(),\n            nn.ReLU(),\n            nn.Dropout(),] * (layers-2),\n            nn.LazyLinear(368),\n        )\n    \n    def forward(self, x):\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.874999Z","iopub.execute_input":"2024-05-04T16:48:04.875289Z","iopub.status.idle":"2024-05-04T16:48:04.883073Z","shell.execute_reply.started":"2024-05-04T16:48:04.875268Z","shell.execute_reply":"2024-05-04T16:48:04.882251Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"net = MLP(12, 512).to(device)\ntry:\n    weights = torch.load('/kaggle/input/dict.pth', map_location=device)\n    net.load_state_dict(weights)\n    print(\"Weights loaded. \")\nexcept:\n    print(\"Weights not loaded. \")\nprint(net)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.884217Z","iopub.execute_input":"2024-05-04T16:48:04.884529Z","iopub.status.idle":"2024-05-04T16:48:04.923879Z","shell.execute_reply.started":"2024-05-04T16:48:04.884500Z","shell.execute_reply":"2024-05-04T16:48:04.923115Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n  warnings.warn('Lazy modules are a new feature under heavy development '\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"def r2score(pred, targ):\n    targ_mean = torch.mean(targ)\n    ss_total = torch.sum((targ - targ_mean) ** 2)\n    ss_residual = torch.sum((targ - pred) ** 2)\n    r2 = 1 - (ss_residual / ss_total)\n    return r2\n\ncriterion = nn.MSELoss()\n    \noptimizer = optim.Adam(net.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.925036Z","iopub.execute_input":"2024-05-04T16:48:04.925306Z","iopub.status.idle":"2024-05-04T16:48:04.931024Z","shell.execute_reply.started":"2024-05-04T16:48:04.925284Z","shell.execute_reply":"2024-05-04T16:48:04.930102Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"lowest_loss = float('inf')\n\naccus, losses = [[],[]], [[],[]]\nepoch = 0\nlast_epoch = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.932147Z","iopub.execute_input":"2024-05-04T16:48:04.932757Z","iopub.status.idle":"2024-05-04T16:48:04.940769Z","shell.execute_reply.started":"2024-05-04T16:48:04.932734Z","shell.execute_reply":"2024-05-04T16:48:04.939941Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"try:\n    for idx, chunk in enumerate(train_chunks):\n    # if True:\n        patience = 0\n        timer.start(f'Train {num_epochs} epochs on chunk {idx}')\n        train_loader, val_loader = get_chunk_loader(chunk)\n        while epoch < num_epochs:\n            epoch += 1\n            t0 = time.time()\n            net.train()\n            train_loss = 0.0\n            train_accu = 0.0\n            num_train_batches = 0\n\n            for inp, outp in tqdm(train_loader):\n                inp, outp = inp.to(device, non_blocking = True), outp.to(device, non_blocking = True)\n                out_h = net(inp)\n                crit = criterion(out_h, outp)\n                loss = crit.item()\n                train_loss += loss\n                accu = r2score(out_h, outp)\n                train_accu += accu\n                crit.backward()\n                optimizer.step()\n                optimizer.zero_grad()\n                num_train_batches += 1\n            avg_train_loss = train_loss / num_train_batches\n            losses[0].append(avg_train_loss)\n            avg_train_accu = train_accu / num_train_batches\n            accus[0].append(avg_train_accu.item())\n\n            net.eval()\n            val_loss = 0.0\n            val_accu = 0.0\n            num_val_batches = 0\n\n            with torch.no_grad():\n                for inp, outp in tqdm(val_loader):\n    #                 inp, outp = [inps.to(device, non_blocking=True) for inps in inp], outp.cuda()\n                    inp, outp = inp.to(device, non_blocking = True), outp.to(device, non_blocking = True)\n                    out_h = net(inp)\n                    crit = criterion(out_h, outp)\n                    val_loss += crit.item()\n                    accu = r2score(out_h, outp)\n                    val_accu += accu\n                    num_val_batches += 1\n            try:\n                last_val_loss = avg_val_loss\n            except:\n                last_val_loss = lowest_loss\n            avg_val_loss = val_loss / num_val_batches\n            losses[1].append(avg_val_loss)\n            avg_val_accu = val_accu / num_val_batches\n            accus[1].append(avg_val_accu.item())\n\n            if avg_val_loss < lowest_loss:\n                torch.save(net.state_dict(), 'best.pth')  # 保存模型参数而不是整个模型\n                lowest_loss = avg_val_loss\n\n            t1 = time.time()\n            print(f'Chunk {idx}:{epoch - last_epoch} | Epoch {epoch}/{num_epochs} > Time Cost: {t1-t0:.2f}s | patience: {patience} \\n\\t', \n                  f'Train Loss: {avg_train_loss:.3f} | Val Loss: {avg_val_loss:.3f}\\n\\t',\n                  f'Train Accu: {avg_train_accu:.3f} | Val Accu: {avg_val_accu:.3f}')\n            if avg_train_loss < avg_val_loss and last_val_loss < avg_val_loss:\n                patience += 1\n            else:\n                patience = 0\n            if patience >= max_patience:\n                print(f'{max_patience} epochs had val loss bigger than train loss and validation loss increased. Exit for next chunk of data')\n                patience = 0\n                last_epoch = epoch\n                del(chunk)\n                break\n        else:\n            break\nexcept:\n    print('Train End')\ntimer.stop()\ntorch.save(net.state_dict(), \"latest.pth\") \ngraph(accus, losses, 'Train')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:48:04.941942Z","iopub.execute_input":"2024-05-04T16:48:04.942229Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 256 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"train_in.shape = (80000, 556)\ntrain_out.shape = (80000, 368)\nval_in.shape = (20000, 556)\nval_out.shape = (20000, 368)\nlen(train_loader) = 223\nlen(val_loader) = 56\n0 Load datasets... Time Cost: 0.211s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.75it/s] \n100%|██████████| 56/56 [00:09<00:00,  5.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:1 | Epoch 1/50 > Time Cost: 25.92s | patience: 0 \n\t Train Loss: 623.656 | Val Loss: 669.767\n\t Train Accu: 0.097 | Val Accu: 0.025\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.44it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:2 | Epoch 2/50 > Time Cost: 26.74s | patience: 0 \n\t Train Loss: 472.603 | Val Loss: 638.246\n\t Train Accu: 0.316 | Val Accu: 0.071\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:17<00:00, 12.95it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:3 | Epoch 3/50 > Time Cost: 27.61s | patience: 0 \n\t Train Loss: 328.560 | Val Loss: 398.219\n\t Train Accu: 0.524 | Val Accu: 0.419\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.14it/s] \n100%|██████████| 56/56 [00:11<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:4 | Epoch 4/50 > Time Cost: 28.84s | patience: 0 \n\t Train Loss: 253.281 | Val Loss: 215.553\n\t Train Accu: 0.633 | Val Accu: 0.685\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:17<00:00, 12.91it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:5 | Epoch 5/50 > Time Cost: 27.84s | patience: 0 \n\t Train Loss: 177.163 | Val Loss: 178.483\n\t Train Accu: 0.744 | Val Accu: 0.740\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:20<00:00, 10.65it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:6 | Epoch 6/50 > Time Cost: 31.52s | patience: 0 \n\t Train Loss: 117.509 | Val Loss: 114.427\n\t Train Accu: 0.830 | Val Accu: 0.834\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.37it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:7 | Epoch 7/50 > Time Cost: 27.67s | patience: 0 \n\t Train Loss: 95.477 | Val Loss: 117.898\n\t Train Accu: 0.862 | Val Accu: 0.829\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.51it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:8 | Epoch 8/50 > Time Cost: 26.70s | patience: 1 \n\t Train Loss: 88.490 | Val Loss: 145.356\n\t Train Accu: 0.872 | Val Accu: 0.789\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:20<00:00, 10.73it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:9 | Epoch 9/50 > Time Cost: 30.95s | patience: 2 \n\t Train Loss: 84.431 | Val Loss: 133.699\n\t Train Accu: 0.878 | Val Accu: 0.806\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.51it/s] \n100%|██████████| 56/56 [00:09<00:00,  5.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:10 | Epoch 10/50 > Time Cost: 26.47s | patience: 0 \n\t Train Loss: 82.238 | Val Loss: 146.833\n\t Train Accu: 0.881 | Val Accu: 0.788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.24it/s] \n100%|██████████| 56/56 [00:09<00:00,  5.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:11 | Epoch 11/50 > Time Cost: 26.76s | patience: 1 \n\t Train Loss: 80.328 | Val Loss: 131.357\n\t Train Accu: 0.884 | Val Accu: 0.810\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:17<00:00, 13.03it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:12 | Epoch 12/50 > Time Cost: 27.41s | patience: 0 \n\t Train Loss: 80.093 | Val Loss: 127.489\n\t Train Accu: 0.884 | Val Accu: 0.815\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:18<00:00, 12.24it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:13 | Epoch 13/50 > Time Cost: 28.68s | patience: 0 \n\t Train Loss: 78.788 | Val Loss: 131.102\n\t Train Accu: 0.886 | Val Accu: 0.810\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.59it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:14 | Epoch 14/50 > Time Cost: 26.56s | patience: 1 \n\t Train Loss: 78.329 | Val Loss: 130.880\n\t Train Accu: 0.886 | Val Accu: 0.811\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.58it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:15 | Epoch 15/50 > Time Cost: 26.62s | patience: 0 \n\t Train Loss: 77.376 | Val Loss: 131.178\n\t Train Accu: 0.888 | Val Accu: 0.810\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:17<00:00, 12.91it/s] \n100%|██████████| 56/56 [00:09<00:00,  5.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:16 | Epoch 16/50 > Time Cost: 27.29s | patience: 1 \n\t Train Loss: 76.804 | Val Loss: 113.231\n\t Train Accu: 0.889 | Val Accu: 0.836\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.57it/s] \n100%|██████████| 56/56 [00:09<00:00,  5.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:17 | Epoch 17/50 > Time Cost: 26.34s | patience: 0 \n\t Train Loss: 75.403 | Val Loss: 137.754\n\t Train Accu: 0.891 | Val Accu: 0.801\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.53it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:18 | Epoch 18/50 > Time Cost: 26.60s | patience: 1 \n\t Train Loss: 74.771 | Val Loss: 138.123\n\t Train Accu: 0.892 | Val Accu: 0.800\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.66it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:19 | Epoch 19/50 > Time Cost: 26.43s | patience: 2 \n\t Train Loss: 74.928 | Val Loss: 120.867\n\t Train Accu: 0.891 | Val Accu: 0.825\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 223/223 [00:16<00:00, 13.43it/s] \n100%|██████████| 56/56 [00:10<00:00,  5.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Chunk 0:20 | Epoch 20/50 > Time Cost: 26.85s | patience: 0 \n\t Train Loss: 74.304 | Val Loss: 130.896\n\t Train Accu: 0.892 | Val Accu: 0.810\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/223 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# 清理\ndel(inp)\ndel(outp)\ndel(train_dataset)\ndel(train_loader)\ndel(val_dataset)\ndel(val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Model","metadata":{}},{"cell_type":"code","source":"try:\n    del(net)\n    print('Latest net released!')\nexcept:\n    print('No model trained')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = Net().to(device)\n# net.load_state_dict(torch.load('/kaggle/input/atmospred/pytorch/trained.pth/1/20240502-001.pth', map_location=device))\nnet.load_state_dict(torch.load('best.pth', map_location=device))\nprint('Load best model.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MLP_Dataset(test_in, test_out)\ntest_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\nprint(f'{len(test_dataset) = }')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timer.start('Run Test')\nnet.eval()\ntest_loss = 0.0\ntest_accu = 0.0\nnum_test_batches = 0\n\nwith torch.no_grad():\n    for i, (inp, outp) in enumerate(tqdm(test_loader)):\n        inp, outp = [inps.to(device, non_blocking=True) for inps in inp], outp.to(device)\n        out_h = net(inp)\n        crit = criterion(out_h, outp)\n        test_loss += crit.item()\n        test_accu += r2score(out_h, outp)\n        num_test_batches += 1\n\navg_test_loss = test_loss / num_test_batches\navg_test_accu = test_accu / num_test_batches\n\nprint(f'Test Loss: {avg_test_loss:.3f} | Test Accu: {avg_test_accu:.3f}')\ntimer.stop()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 清理变量\ndel(test_dataset)\ndel(test_loader)\ndel(out_h)\ndel(inp, outp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}